import os
import logging
import time
import sys
import asyncio
import json
import cv2
import numpy as np
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from dotenv import load_dotenv
from werkzeug.utils import secure_filename
from ultralytics import YOLO
import google.generativeai as genai
from openai import OpenAI

# --- TH∆Ø VI·ªÜN MCP ---
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# --- C·∫•u h√¨nh & Logging ---
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
log = logging

app = Flask(__name__, static_folder='static') 
CORS(app)

# C·∫•u h√¨nh th∆∞ m·ª•c upload
UPLOAD_FOLDER = Path("uploads")
UPLOAD_FOLDER.mkdir(parents=True, exist_ok=True)
app.config['UPLOAD_FOLDER'] = str(UPLOAD_FOLDER)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}

async def call_mcp_lookup_async(query_text):
    """
    K·∫øt n·ªëi t·ªõi mcp_server.py an to√†n, h·ªó tr·ª£ ti·∫øng Vi·ªát tr√™n Windows.
    """
    # 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n file server (tuy·ªát ƒë·ªëi)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    server_script = os.path.join(current_dir, "mcp_server.py")

    if not os.path.exists(server_script):
        log.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file server t·∫°i: {server_script}")
        return "L·ªói h·ªá th·ªëng: Thi·∫øu file mcp_server.py"

    # 2. C·∫•u h√¨nh m√¥i tr∆∞·ªùng UTF-8 cho ti·∫øn tr√¨nh con (QUAN TR·ªåNG)
    env = os.environ.copy()
    env["PYTHONUTF8"] = "1"          # B·∫Øt bu·ªôc Python d√πng UTF-8
    env["PYTHONIOENCODING"] = "utf-8" # B·∫Øt bu·ªôc IO d√πng UTF-8
    env["NB_LOG_LEVEL"] = "ERROR"    # Gi·∫£m log r√°c c·ªßa th∆∞ vi·ªán

    # 3. C·∫•u h√¨nh tham s·ªë Server
    server_params = StdioServerParameters(
        command=sys.executable, # D√πng python hi·ªán t·∫°i
        args=[server_script], 
        env=env 
    )

    try:
        # 4. K·∫øt n·ªëi v√† g·ªçi Tool
        async with stdio_client(server_params) as (read, write):
            async with ClientSession(read, write) as session:
                await session.initialize()
                
                # G·ªçi tool 'luat_lookup' ƒë√£ ƒë·ªãnh nghƒ©a b√™n server
                result = await session.call_tool("luat_lookup", arguments={"query": query_text})
                
                if result.content and hasattr(result.content[0], 'text'):
                    return result.content[0].text
                
                return "Server MCP k·∫øt n·ªëi th√†nh c√¥ng nh∆∞ng kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu text."
                
    except Exception as e:
        log.error(f"üî• L·ªói k·∫øt n·ªëi MCP: {e}")
        return f"H·ªá th·ªëng tra c·ª©u ƒëang kh·ªüi ƒë·ªông ho·∫∑c g·∫∑p l·ªói. Chi ti·∫øt: {e}"

def search_vbpl_sync(query):
    """H√†m wrapper ƒë·ªÉ Flask (Sync) g·ªçi ƒë∆∞·ª£c MCP (Async)."""
    try:
        return asyncio.run(call_mcp_lookup_async(query))
    except Exception as e:
        return f"L·ªói Async Loop: {e}"

def remove_accents(input_str):
    """
    X√≥a d·∫•u Ti·∫øng Vi·ªát kh·ªèi m·ªôt chu·ªói ƒë·ªÉ v·∫Ω l√™n ·∫£nh OpenCV (tr√°nh l·ªói ???).
    """
    if not input_str:
        return ""
    s1 = u'√Ä√Å√Ç√É√à√â√ä√å√ç√í√ì√î√ï√ô√ö√ù√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√ΩƒÇƒÉƒêƒëƒ®ƒ©≈®≈©∆†∆°∆Ø∆∞·∫†·∫°·∫¢·∫£·∫§·∫•·∫¶·∫ß·∫®·∫©·∫™·∫´·∫¨·∫≠·∫Æ·∫Ø·∫∞·∫±·∫≤·∫≥·∫¥·∫µ·∫∂·∫∑·∫∏·∫π·∫∫·∫ª·∫º·∫Ω·∫æ·∫ø·ªÄ·ªÅ·ªÇ·ªÉ·ªÑ·ªÖ·ªÜ·ªá·ªà·ªâ·ªä·ªã·ªå·ªç·ªé·ªè·ªê·ªë·ªí·ªì·ªî·ªï·ªñ·ªó·ªò·ªô·ªö·ªõ·ªú·ªù·ªû·ªü·ª†·ª°·ª¢·ª£·ª§·ª•·ª¶·ªß·ª®·ª©·ª™·ª´·ª¨·ª≠·ªÆ·ªØ·ª∞·ª±'
    s0 = u'AAAAEEEIIOOOOUUYaaaaeeeiioooouuyAadDiIUuOoUuAaAaAaAaAaAaAaAaAaAaAaAaEeEeEeEeEeEeEeEeIiIiOoOoOoOoOoOoOoOoOoOoOoOoUuUuUuUuUuUuUu'
    s = ''
    try:
        input_str = str(input_str)
    except:
        return str(input_str)
        
    for c in input_str:
        if c in s1:
            s += s0[s1.index(c)]
        else:
            s += c
    return s

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# --- 1. C·∫§U H√åNH AI CHAT ---
try:
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    gemini_model = genai.GenerativeModel('gemini-2.5-flash')
except Exception as e:
    gemini_model = None
    logging.warning(f"‚ö†Ô∏è L·ªói c·∫•u h√¨nh Gemini: {e}")

try:
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    response = openai_client.responses.create(
    model="gpt-5-nano",
    input="write a haiku about ai",
    store=True,
    )
except Exception as e:
    openai_client = None
    logging.warning(f"‚ö†Ô∏è L·ªói c·∫•u h√¨nh OpenAI: {e}")

try:
    deepseek_client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=os.getenv("OPENROUTER_API_KEY")
    )
except Exception as e:
    deepseek_client = None
    logging.warning(f"‚ö†Ô∏è L·ªói c·∫•u h√¨nh DeepSeek: {e}")

# --- 2. LOAD MODEL COMPUTER VISION ---

# A. Model Bi·ªÉn B√°o
SIGN_MODEL_PATH = Path("C:/Users/hovan/OneDrive/Desktop/AII/TRAFFIC_SIGNS/runs_yolo/yolov13_custom_train2/weights/best.pt")
try:
    if SIGN_MODEL_PATH.exists():
        sign_model = YOLO(str(SIGN_MODEL_PATH))
        logging.info("‚úÖ Loaded Sign Model")
    else:
        sign_model = None
        logging.error(f"‚ùå Sign Model not found at {SIGN_MODEL_PATH}")
except Exception as e:
    sign_model = None
    logging.error(f"‚ùå Error loading Sign Model: {e}")

# B. Model Ng·ªß G·∫≠t
SLEEP_MODEL_PATH = Path("C:/Users/hovan/OneDrive/Desktop/AII/TrainModel/models/best_drowsy.pt")
try:
    if SLEEP_MODEL_PATH.exists():
        sleep_model = YOLO(str(SLEEP_MODEL_PATH))
        logging.info("‚úÖ Loaded Sleep Model")
    else:
        sleep_model = None
        logging.error(f"‚ùå Sleep Model not found at {SLEEP_MODEL_PATH}")
except Exception as e:
    sleep_model = None
    logging.error(f"‚ùå Error loading Sleep Model: {e}")

# Define sleep detection class names
SLEEP_CLASS_NAMES = {
    0: "alert",
    1: "mat_nham"  # Drowsy/sleepy
}

# Load face detector (OpenCV DNN)
FACE_PROTO = Path("C:/Users/hovan/OneDrive/Desktop/AII/TrainModel/models/deploy.prototxt.txt")
FACE_MODEL = Path("C:/Users/hovan/OneDrive/Desktop/AII/TrainModel/models/res10_300x300_ssd_iter_140000.caffemodel")
try:
    if FACE_PROTO.exists() and FACE_MODEL.exists():
        face_net = cv2.dnn.readNetFromCaffe(str(FACE_PROTO), str(FACE_MODEL))
        logging.info("‚úÖ Loaded Face Detector (DNN)")
    else:
        face_net = None
        logging.warning(f"‚ö†Ô∏è Face detector files not found at {FACE_PROTO} and {FACE_MODEL}; face detection disabled.")
except Exception as e:
    face_net = None
    logging.error(f"‚ùå Error loading face detector: {e}")


# --- 3. H√ÄM X·ª¨ L√ù LOGIC (Backend) ---

def detect_sign_logic(image_path):
    if not sign_model: 
        return {"result": "‚ùå L·ªói: Model ch∆∞a load.", "image_path": None, "detections": []}

    try:
        img = cv2.imread(image_path)
        if img is None: return {"result": "‚ùå L·ªói ƒë·ªçc ·∫£nh", "image_path": None}

        # D·ª± ƒëo√°n
        results = sign_model.predict(source=img, conf=0.25, save=False, verbose=False)
        detections = []
        found = False

        # L·∫•y t√™n class tr·ª±c ti·∫øp t·ª´ model
        names = sign_model.names

        for r in results:
            for box in r.boxes:
                found = True
                cls_id = int(box.cls[0])
                conf = float(box.conf[0])
                
                # L·∫•y t√™n class g·ªëc (c√≥ d·∫•u)
                try:
                    display_name = names[cls_id]
                except Exception:
                    display_name = str(cls_id)
                
                # 1. Label d√πng ƒë·ªÉ tr·∫£ v·ªÅ JSON (Gi·ªØ nguy√™n Ti·∫øng Vi·ªát c√≥ d·∫•u)
                label_full = display_name 

                # 2. Label d√πng ƒë·ªÉ v·∫Ω l√™n ·∫£nh (X√≥a d·∫•u ƒë·ªÉ kh√¥ng b·ªã l·ªói ???)
                label_no_accent = remove_accents(display_name)
                draw_text = f"{label_no_accent} {conf:.0%}"

                # V·∫Ω khung
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # V·∫Ω nh√£n n·ªÅn
                (w, h), _ = cv2.getTextSize(draw_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                cv2.rectangle(img, (x1, y1 - 25), (x1 + w, y1), (0, 255, 0), -1)
                
                # V·∫Ω ch·ªØ (D√πng bi·∫øn draw_text kh√¥ng d·∫•u)
                cv2.putText(img, draw_text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                
                detections.append({"class": label_full, "confidence": conf})

        filename = "checked_sign_" + os.path.basename(image_path)
        save_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        cv2.imwrite(save_path, img)

        msg = f"‚úÖ T√¨m th·∫•y {len(detections)} bi·ªÉn b√°o." if found else "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y bi·ªÉn b√°o n√†o."
        if found:
            # T·∫°o danh s√°ch t√™n bi·ªÉn b√°o duy nh·∫•t ƒë·ªÉ hi·ªÉn th·ªã th√¥ng b√°o
            unique_signs = list(set([d['class'] for d in detections]))
            msg += "\n" + ", ".join(unique_signs)

        return {"result": msg, "detections": detections, "image_path": filename}
    except Exception as e:
        logging.error(f"L·ªói detect_sign_logic: {e}")
        return {"result": f"L·ªói x·ª≠ l√Ω: {e}", "image_path": None}


def detect_sleep_logic(filepath):
    if not sleep_model or not face_net:
        return {"error": "Model Ng·ªß g·∫≠t ho·∫∑c Face Detector ch∆∞a s·∫µn s√†ng."}

    try:
        image = cv2.imread(str(filepath))
        if image is None:
            return {"error": "Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh."}
        
        (h, w) = image.shape[:2]

        # Face detection (OpenCV DNN)
        blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))
        face_net.setInput(blob)
        detections = face_net.forward()

        best_face = None
        best_confidence = 0.0

        for i in range(0, detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence > 0.5:  # threshold
                if confidence > best_confidence:
                    best_confidence = confidence
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (startX, startY, endX, endY) = box.astype("int")
                    (startX, startY) = (max(0, startX), max(0, startY))
                    (endX, endY) = (min(w - 1, endX), min(h - 1, endY))
                    best_face = (startX, startY, endX, endY)

        if best_face is None:
            return {"result": "‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t", "image_path": None}

        (startX, startY, endX, endY) = best_face
        face_width = endX - startX
        if face_width < 10:
            return {"result": f"‚ùå L·ªói ph√°t hi·ªán khu√¥n m·∫∑t (width: {face_width}px)", "image_path": None}

        face_roi = image[startY:endY, startX:endX]
        if face_roi.size == 0:
            return {"result": "‚ùå K√≠ch th∆∞·ªõc khu√¥n m·∫∑t kh√¥ng h·ª£p l·ªá", "image_path": None}

        # Run detection on cropped face
        results = sleep_model.predict(source=face_roi, verbose=False)

        result_text = ""
        is_sleepy = False

        if hasattr(results[0], 'boxes') and results[0].boxes is not None:
            if len(results[0].boxes) == 0:
                result_text = "‚úÖ PH√ÅT HI·ªÜN: T·ªàNH T√ÅO"
                color = (0, 255, 0)
                draw_label = "AWAKE (No detections)"
                cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)
                cv2.putText(image, draw_label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            else:
                for box in results[0].boxes:
                    class_id = int(box.cls.item())
                    confidence = float(box.conf.item())
                    class_name = SLEEP_CLASS_NAMES.get(class_id, "unknown")

                    if class_id == 1:
                        is_sleepy = True

                    x1, y1, x2, y2 = [int(v) for v in box.xyxy[0].tolist()]
                    # Map t·ªça ƒë·ªô t·ª´ face_roi ra ·∫£nh g·ªëc
                    x1_abs = x1 + startX
                    y1_abs = y1 + startY
                    x2_abs = x2 + startX
                    y2_abs = y2 + startY

                    box_color = (0, 0, 255) if class_id == 1 else (0, 255, 0)
                    # class_name ·ªü ƒë√¢y th∆∞·ªùng l√† ti·∫øng Anh ho·∫∑c kh√¥ng d·∫•u n√™n v·∫Ω ƒë∆∞·ª£c
                    draw_label = f"{class_name} {confidence*100:.0f}%"
                    
                    cv2.rectangle(image, (x1_abs, y1_abs), (x2_abs, y2_abs), box_color, 1)
                    cv2.putText(image, draw_label, (x1_abs, y1_abs - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 1)

                if is_sleepy:
                    result_text = "‚ùå PH√ÅT HI·ªÜN: C√ì NG·ª¶ G·∫¨T"
                    color = (0, 0, 255)
                    draw_label = "SLEEPY"
                else:
                    result_text = "‚úÖ PH√ÅT HI·ªÜN: T·ªàNH T√ÅO"
                    color = (0, 255, 0)
                    draw_label = "AWAKE"

                cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)
                cv2.putText(image, draw_label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        else:
            result_text = "‚ùå L·ªói: Model kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá."

        # Save annotated image
        filename = os.path.basename(filepath)
        image_annotated_name = Path(filename).stem + "_sleep_annotated.jpg"
        image_annotated_path = Path(app.config['UPLOAD_FOLDER']) / image_annotated_name
        cv2.imwrite(str(image_annotated_path), image)

        try:
            Path(filepath).unlink()
        except Exception:
            logging.warning("Kh√¥ng x√≥a ƒë∆∞·ª£c file upload t·∫°m th·ªùi (ng·ªß g·∫≠t).")

        return {"result": result_text, "image_path": str(image_annotated_name)}
    except Exception as e:
        logging.exception("L·ªói trong detect_sleep_logic:")
        try:
            Path(filepath).unlink()
        except Exception:
            pass
        return {"error": f"L·ªói khi x·ª≠ l√Ω file: {e}"}

# --- 4. ROUTES API ---

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/chat-law-lookup', methods=['POST'])
def handle_law_lookup():
    data = request.json
    query = data.get('message', '')
    if not query: return jsonify({"error": "N·ªôi dung tr·ªëng"}), 400
    
    log.info(f"üîç User h·ªèi: {query}")
    
    # 1. G·ªçi MCP ƒë·ªÉ l·∫•y d·ªØ li·ªáu th√¥ (Snippet + Raw Text)
    raw_context = search_vbpl_sync(query)
    
    # 2. D√πng AI ƒë·ªÉ l·ªçc v√† tr·∫£ l·ªùi ng·∫Øn g·ªçn
    final_response = raw_context # M·∫∑c ƒë·ªãnh tr·∫£ v·ªÅ th√¥ n·∫øu AI l·ªói
    
    # ∆Øu ti√™n d√πng OpenAI ho·∫∑c Gemini ƒë·ªÉ format ƒë·∫πp
    try:
        if openai_client:
            prompt = f"""
            B·∫°n l√† lu·∫≠t s∆∞ giao th√¥ng AI. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu t√¨m ki·∫øm th√¥ t·ª´ internet:
            
            {raw_context}
            
            NHI·ªÜM V·ª§: 
            1. Tr·∫£ l·ªùi c√¢u h·ªèi: "{query}"
            2. Ch·ªâ d√πng th√¥ng tin t·ª´ d·ªØ li·ªáu tr√™n (ƒë·∫∑c bi·ªát ch√∫ √Ω Ngh·ªã ƒë·ªãnh 168 ho·∫∑c quy ƒë·ªãnh 2025).
            3. Tr√¨nh b√†y ng·∫Øn g·ªçn, d√πng Markdown (in ƒë·∫≠m m·ª©c ph·∫°t).
            """
            resp = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            final_response = resp.choices[0].message.content
            
        elif gemini_model:
            prompt = f"D·ª±a v√†o d·ªØ li·ªáu th√¥ sau:\n{raw_context}\n\nH√£y tr·∫£ l·ªùi c√¢u h·ªèi: '{query}' ng·∫Øn g·ªçn, ch√≠nh x√°c theo lu·∫≠t m·ªõi nh·∫•t 2025."
            resp = gemini_model.generate_content(prompt)
            final_response = resp.text
            
    except Exception as e:
        log.error(f"L·ªói AI t·ªïng h·ª£p: {e}")
        # N·∫øu AI l·ªói, v·∫´n tr·∫£ v·ªÅ d·ªØ li·ªáu th√¥ t·ª´ MCP ƒë·ªÉ user ƒë·ªçc
        pass 
        
    return jsonify({"response": final_response})


# --- Chat Handlers ---
SYSTEM_PROMPT = "B·∫°n l√† tr·ª£ l√Ω l√°i xe AI th√¥ng minh. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch."

def call_gemini(parts, history):
    if not gemini_model: return "Ch∆∞a c·∫•u h√¨nh Gemini"
    try:
        chat = gemini_model.start_chat(history=[])
        new_parts = [p['text'] for p in parts if 'text' in p]
        return chat.send_message(new_parts).text
    except Exception as e: return f"L·ªói Gemini: {e}"

def call_openai(parts, history):
    if not openai_client: return "Ch∆∞a c·∫•u h√¨nh OpenAI"
    try:
        text = " ".join([p.get('text', '') for p in parts])
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini", messages=[{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": text}]
        )
        return resp.choices[0].message.content
    except Exception as e: return f"L·ªói OpenAI: {e}"

def call_deepseek(parts, history):
    if not deepseek_client: return "Ch∆∞a c·∫•u h√¨nh DeepSeek"
    try:
        text = " ".join([p.get('text', '') for p in parts])
        resp = deepseek_client.chat.completions.create(
            model="deepseek/deepseek-chat-v3.1", messages=[{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": text}]
        )
        return resp.choices[0].message.content
    except Exception as e: return f"L·ªói DeepSeek: {e}"

@app.route('/chat', methods=['POST'])
def handle_chat():
    data = request.json
    return jsonify({"response": call_gemini(data.get('parts', []), data.get('history', []))})

@app.route('/chat-openai', methods=['POST'])
def handle_openai():
    data = request.json
    return jsonify({"response": call_openai(data.get('parts', []), data.get('history', []))})

@app.route('/chat-deepseek', methods=['POST'])
def handle_deepseek():
    data = request.json
    return jsonify({"response": call_deepseek(data.get('parts', []), data.get('history', []))})

@app.route('/chat-aggregate', methods=['POST'])
def handle_aggregate():
    data = request.json
    parts = data.get('parts', [])
    hist = data.get('history', [])
    with ThreadPoolExecutor(max_workers=3) as exe:
        f1 = exe.submit(call_gemini, parts, hist)
        f2 = exe.submit(call_openai, parts, hist)
        f3 = exe.submit(call_deepseek, parts, hist)
        results = {"gemini": f1.result(), "openai": f2.result(), "deepseek": f3.result()}
    
    summary_prompt = f"T·ªïng h·ª£p 3 c√¢u tr·∫£ l·ªùi sau th√†nh 1 c√¢u t·ªët nh·∫•t:\n1. {results['gemini']}\n2. {results['openai']}\n3. {results['deepseek']}"
    final = call_gemini([{'text': summary_prompt}], [])
    return jsonify({"final_answer": final, "sources": results})


# --- Detection Endpoints ---
@app.route('/detect-sign', methods=['POST'])
def route_detect_sign():
    if 'file' not in request.files: return jsonify({"error": "No file"}), 400
    file = request.files['file']
    if file and allowed_file(file.filename):
        filename = f"{int(time.time())}_{secure_filename(file.filename)}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        return jsonify(detect_sign_logic(filepath))
    return jsonify({"error": "Invalid file"}), 400

@app.route('/detect-sleep', methods=['POST'])
def route_detect_sleep():
    if 'file' not in request.files: return jsonify({"error": "No file"}), 400
    file = request.files['file']
    if file and allowed_file(file.filename):
        filename = f"{int(time.time())}_{secure_filename(file.filename)}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        return jsonify(detect_sleep_logic(filepath))
    return jsonify({"error": "Invalid file"}), 400

if __name__ == '__main__':
    app.run(debug=True, port=5000, use_reloader=False)