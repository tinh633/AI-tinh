{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826a6d04",
   "metadata": {},
   "source": [
    "15:24 09/11/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Deque, Tuple, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===========================\n",
    "# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N & THAM S·ªê\n",
    "# ===========================\n",
    "\n",
    "DATA_ROOT = Path(\"/home/gess/Documents/sub/TrainModel\")\n",
    "MODEL_DIR = DATA_ROOT / \"models\"\n",
    "BEST_MODEL = MODEL_DIR / \"best_drowsy.pt\"  # ƒë√£ train xong ·ªü train_drowsy.py\n",
    "\n",
    "# Class name ph·∫£i tr√πng l√∫c train\n",
    "CLS_OPEN = \"open_eye\"\n",
    "CLS_CLOSED = \"closed_eye\"\n",
    "\n",
    "# Tham s·ªë drowsy\n",
    "HISTORY_LEN = 30        # s·ªë frame l∆∞u history (kho·∫£ng 1 gi√¢y n·∫øu 30fps)\n",
    "DROWSY_THRESHOLD = 0.6  # t·ªâ l·ªá closed_eye / (open+closed) trong history\n",
    "MIN_EYES_PER_FRAME = 1  # s·ªë m·∫Øt min ƒë·ªÉ frame ƒë∆∞·ª£c t√≠nh\n",
    "\n",
    "# Confidence ng∆∞·ª°ng ƒë·ªÉ t√≠nh\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ===========================\n",
    "# H√ÄM TI·ªÜN √çCH\n",
    "# ===========================\n",
    "\n",
    "def load_model(model_path: Path) -> YOLO:\n",
    "    if not model_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y model: {model_path}\")\n",
    "        sys.exit(1)\n",
    "    print(f\"[üöÄ] Load model: {model_path}\")\n",
    "    model = YOLO(str(model_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def decode_counts_from_result(\n",
    "    result,\n",
    "    cls_open: str = CLS_OPEN,\n",
    "    cls_closed: str = CLS_CLOSED,\n",
    "    conf_thresh: float = CONF_THRESH,\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    ƒê·∫øm s·ªë open_eye v√† closed_eye trong 1 k·∫øt qu·∫£ YOLO.\n",
    "\n",
    "    Return:\n",
    "        (num_open, num_closed)\n",
    "    \"\"\"\n",
    "    names = result.names\n",
    "    num_open = 0\n",
    "    num_closed = 0\n",
    "\n",
    "    if result.boxes is None or len(result.boxes) == 0:\n",
    "        return 0, 0\n",
    "\n",
    "    for b in result.boxes:\n",
    "        cls_id = int(b.cls[0].item())\n",
    "        conf = float(b.conf[0].item())\n",
    "        if conf < conf_thresh:\n",
    "            continue\n",
    "        cls_name = names.get(cls_id, str(cls_id))\n",
    "        if cls_name == cls_open:\n",
    "            num_open += 1\n",
    "        elif cls_name == cls_closed:\n",
    "            num_closed += 1\n",
    "    return num_open, num_closed\n",
    "\n",
    "\n",
    "def update_drowsy_history(\n",
    "    history: Deque[Tuple[int, int]],\n",
    "    num_open: int,\n",
    "    num_closed: int,\n",
    "    maxlen: int = HISTORY_LEN,\n",
    ") -> Tuple[float, int, int]:\n",
    "    \"\"\"\n",
    "    C·∫≠p nh·∫≠t history (deque) v·ªõi (open, closed) c·ªßa frame m·ªõi.\n",
    "    Tr·∫£ v·ªÅ:\n",
    "        - closed_ratio (t·ªâ l·ªá closed / total)\n",
    "        - total_open\n",
    "        - total_closed\n",
    "    \"\"\"\n",
    "    history.append((num_open, num_closed))\n",
    "    if len(history) > maxlen:\n",
    "        history.popleft()\n",
    "\n",
    "    total_open = sum(o for o, _ in history)\n",
    "    total_closed = sum(c for _, c in history)\n",
    "    total = total_open + total_closed\n",
    "    closed_ratio = (total_closed / total) if total > 0 else 0.0\n",
    "    return closed_ratio, total_open, total_closed\n",
    "\n",
    "\n",
    "def draw_info(\n",
    "    frame: np.ndarray,\n",
    "    num_open: int,\n",
    "    num_closed: int,\n",
    "    closed_ratio: float,\n",
    "    is_drowsy: bool,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    V·∫Ω th√¥ng tin l√™n frame: s·ªë m·∫Øt m·ªü/nh·∫Øm, t·ªâ l·ªá, tr·∫°ng th√°i drowsy.\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Bar m·ªù ph√≠a tr√™n\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 80), (0, 0, 0), -1)\n",
    "    alpha = 0.4\n",
    "    frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "    # Text info\n",
    "    base_y = 25\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Open: {num_open}  Closed: {num_closed}\",\n",
    "        (10, base_y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Closed ratio: {closed_ratio:.2f}\",\n",
    "        (10, base_y + 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (255, 255, 0),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "    status_text = \"DROWSY!\" if is_drowsy else \"OK\"\n",
    "    color = (0, 0, 255) if is_drowsy else (0, 255, 0)\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Status: {status_text}\",\n",
    "        (10, base_y + 50),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.8,\n",
    "        color,\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "    # N·∫øu drowsy th√¨ v·∫Ω khung c·∫£nh b√°o\n",
    "    if is_drowsy:\n",
    "        cv2.rectangle(frame, (0, 80), (w - 1, h - 1), (0, 0, 255), 4)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# WEBCAM REALTIME\n",
    "# ===========================\n",
    "\n",
    "def run_webcam(\n",
    "    model: YOLO,\n",
    "    cam_index: int = 0,\n",
    "    history_len: int = HISTORY_LEN,\n",
    "    drowsy_thresh: float = DROWSY_THRESHOLD,\n",
    "):\n",
    "    print(f\"[üé•] ƒêang m·ªü webcam {cam_index}...\")\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[‚ùå] Kh√¥ng m·ªü ƒë∆∞·ª£c webcam, th·ª≠ index kh√°c (0,1,2,...) ho·∫∑c ki·ªÉm tra quy·ªÅn.\")\n",
    "        return\n",
    "\n",
    "    history: Deque[Tuple[int, int]] = deque(maxlen=history_len)\n",
    "\n",
    "    print(\"[INFO] Nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[‚ùå] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame t·ª´ webcam.\")\n",
    "            break\n",
    "\n",
    "        # YOLO expect BGR ‚Üí OK\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            imgsz=768,\n",
    "            conf=CONF_THRESH,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        if len(results) == 0:\n",
    "            num_open, num_closed = 0, 0\n",
    "        else:\n",
    "            num_open, num_closed = decode_counts_from_result(results[0])\n",
    "\n",
    "        closed_ratio, total_open, total_closed = update_drowsy_history(\n",
    "            history, num_open, num_closed, maxlen=history_len\n",
    "        )\n",
    "\n",
    "        is_drowsy = False\n",
    "        total = total_open + total_closed\n",
    "        if total >= MIN_EYES_PER_FRAME and closed_ratio >= drowsy_thresh:\n",
    "            is_drowsy = True\n",
    "\n",
    "        # V·∫Ω detection box c·ªßa YOLO\n",
    "        plotted = results[0].plot() if len(results) > 0 else frame.copy()\n",
    "\n",
    "        # V·∫Ω info Drowsy\n",
    "        plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "\n",
    "        cv2.imshow(\"Drowsy Detection - Webcam\", plotted)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[‚úÖ] ƒê√£ tho√°t realtime.\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH 1 ·∫¢NH\n",
    "# ===========================\n",
    "\n",
    "def analyze_image(model: YOLO, img_path: str | Path):\n",
    "    img_path = Path(img_path)\n",
    "    if not img_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y ·∫£nh: {img_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"[‚ùå] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {img_path}\")\n",
    "        return\n",
    "\n",
    "    results = model.predict(\n",
    "        source=img,\n",
    "        imgsz=768,\n",
    "        conf=CONF_THRESH,\n",
    "        verbose=False,\n",
    "    )\n",
    "    if len(results) == 0:\n",
    "        print(\"[‚Ñπ] Kh√¥ng c√≥ detection n√†o.\")\n",
    "        cv2.imshow(\"Drowsy - Image\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "    r = results[0]\n",
    "    num_open, num_closed = decode_counts_from_result(r)\n",
    "    total = num_open + num_closed\n",
    "    closed_ratio = (num_closed / total) if total > 0 else 0.0\n",
    "    is_drowsy = closed_ratio >= DROWSY_THRESHOLD and total >= MIN_EYES_PER_FRAME\n",
    "\n",
    "    print(\"===== PH√ÇN T√çCH ·∫¢NH =====\")\n",
    "    print(f\"·∫¢nh       : {img_path}\")\n",
    "    print(f\"Open eyes : {num_open}\")\n",
    "    print(f\"Closed    : {num_closed}\")\n",
    "    print(f\"Closed ratio: {closed_ratio:.2f}\")\n",
    "    print(f\"Tr·∫°ng th√°i: {'DROWSY' if is_drowsy else 'OK'}\")\n",
    "\n",
    "    plotted = r.plot()\n",
    "    plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "    cv2.imshow(\"Drowsy - Image\", plotted)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH FOLDER ·∫¢NH\n",
    "# ===========================\n",
    "\n",
    "def analyze_folder(model: YOLO, folder: str | Path):\n",
    "    folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y folder: {folder}\")\n",
    "        return\n",
    "\n",
    "    exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "    img_files = sorted(\n",
    "        [p for p in folder.rglob(\"*\") if p.suffix.lower() in exts]\n",
    "    )\n",
    "    if not img_files:\n",
    "        print(f\"[‚Ñπ] Folder kh√¥ng c√≥ ·∫£nh h·ª£p l·ªá: {folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[üìÇ] T√¨m th·∫•y {len(img_files)} ·∫£nh trong {folder}\")\n",
    "    for img_path in img_files:\n",
    "        print(f\"\\n--- {img_path} ---\")\n",
    "        analyze_image(model, img_path)\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH VIDEO\n",
    "# ===========================\n",
    "\n",
    "def analyze_video(\n",
    "    model: YOLO,\n",
    "    video_path: str | Path,\n",
    "    history_len: int = HISTORY_LEN,\n",
    "    drowsy_thresh: float = DROWSY_THRESHOLD,\n",
    "):\n",
    "    video_path = Path(video_path)\n",
    "    if not video_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[‚ùå] Kh√¥ng m·ªü ƒë∆∞·ª£c video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    history: Deque[Tuple[int, int]] = deque(maxlen=history_len)\n",
    "    print(\"[INFO] Nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            imgsz=768,\n",
    "            conf=CONF_THRESH,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        if len(results) == 0:\n",
    "            num_open, num_closed = 0, 0\n",
    "        else:\n",
    "            num_open, num_closed = decode_counts_from_result(results[0])\n",
    "\n",
    "        closed_ratio, total_open, total_closed = update_drowsy_history(\n",
    "            history, num_open, num_closed, maxlen=history_len\n",
    "        )\n",
    "        total = total_open + total_closed\n",
    "        is_drowsy = (total >= MIN_EYES_PER_FRAME) and (closed_ratio >= drowsy_thresh)\n",
    "\n",
    "        plotted = results[0].plot() if len(results) > 0 else frame.copy()\n",
    "        plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "\n",
    "        cv2.imshow(\"Drowsy Detection - Video\", plotted)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[‚úÖ] ƒê√£ xong video.\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# MAIN: MENU ƒê∆†N GI·∫¢N (KH√îNG C·∫¶N CLI)\n",
    "# ===========================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ch·∫°y tr·ª±c ti·∫øp file (VS Code Run) ‚Üí hi·ªán menu:\n",
    "      1. Webcam\n",
    "      2. ·∫¢nh\n",
    "      3. Folder ·∫£nh\n",
    "      4. Video\n",
    "    \"\"\"\n",
    "    model = load_model(BEST_MODEL)\n",
    "\n",
    "    print(\"\\n====================\")\n",
    "    print(\"  DROWSY DETECTION  \")\n",
    "    print(\"====================\")\n",
    "    print(\"1) Webcam realtime\")\n",
    "    print(\"2) Ph√¢n t√≠ch 1 ·∫£nh\")\n",
    "    print(\"3) Ph√¢n t√≠ch 1 folder ·∫£nh\")\n",
    "    print(\"4) Ph√¢n t√≠ch 1 video\")\n",
    "    print(\"0) Tho√°t\")\n",
    "    choice = input(\"Ch·ªçn mode (0-4): \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        idx = input(\"Nh·∫≠p camera index (m·∫∑c ƒë·ªãnh 0): \").strip()\n",
    "        cam_idx = int(idx) if idx else 0\n",
    "        run_webcam(model, cam_index=cam_idx)\n",
    "    elif choice == \"2\":\n",
    "        path = input(\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: \").strip()\n",
    "        analyze_image(model, path)\n",
    "    elif choice == \"3\":\n",
    "        folder = input(\"Nh·∫≠p folder ·∫£nh: \").strip()\n",
    "        analyze_folder(model, folder)\n",
    "    elif choice == \"4\":\n",
    "        path = input(\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n video: \").strip()\n",
    "        analyze_video(model, path)\n",
    "    else:\n",
    "        print(\"Tho√°t.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
