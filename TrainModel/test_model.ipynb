{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82363474",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opencv-python pillow requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import threading\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "MODEL_PATH = '/home/gess/Documents/eye_detection_model/professional_eye_detector.pth'\n",
    "IMG_SIZE = (64, 64)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==================== EXACT MODEL ARCHITECTURE ====================\n",
    "class ExactEyeDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExactEyeDetectionModel, self).__init__()\n",
    "        \n",
    "        # EXACT architecture matching the trained model\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 - EXACT sizes\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Block 2 - EXACT sizes  \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Block 3 - EXACT sizes\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Global pooling - EXACT\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "        )\n",
    "        \n",
    "        # Classifier - EXACT sizes (128 * 4 * 4 = 2048)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),  # EXACT: 2048 -> 256\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ==================== SIMPLE & FAST EYE DETECTION ====================\n",
    "class SimpleEyeDetection:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_path = MODEL_PATH\n",
    "        self.load_model()\n",
    "        \n",
    "        # Face detection\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        \n",
    "        # Simple drowsiness detection\n",
    "        self.eye_close_counter = 0\n",
    "        self.eye_close_threshold = 8\n",
    "        \n",
    "        print(\"‚úÖ Simple Eye Detection Initialized!\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load model with EXACT architecture\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.model_path):\n",
    "                # Try to find model\n",
    "                alt_paths = [\n",
    "                    '/home/gess/Documents/sub/Py/hhehee/eye_detection_model/professional_eye_detector.pth',\n",
    "                    './professional_eye_detector.pth',\n",
    "                    'eye_detection_model/professional_eye_detector.pth',\n",
    "                ]\n",
    "                for path in alt_paths:\n",
    "                    if os.path.exists(path):\n",
    "                        self.model_path = path\n",
    "                        print(f\"‚úÖ Found model at: {path}\")\n",
    "                        break\n",
    "            \n",
    "            if os.path.exists(self.model_path):\n",
    "                checkpoint = torch.load(self.model_path, map_location=device)\n",
    "                self.model = ExactEyeDetectionModel().to(device)\n",
    "                \n",
    "                # Load state dict\n",
    "                if 'model_state_dict' in checkpoint:\n",
    "                    state_dict = checkpoint['model_state_dict']\n",
    "                else:\n",
    "                    state_dict = checkpoint\n",
    "                \n",
    "                # Load exactly - should work now\n",
    "                self.model.load_state_dict(state_dict)\n",
    "                self.model.eval()\n",
    "                print(\"üéØ Model loaded EXACTLY!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Model file not found\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model loading failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def fast_preprocess(self, eye_img):\n",
    "        \"\"\"Fast preprocessing\"\"\"\n",
    "        try:\n",
    "            if eye_img is None or eye_img.size == 0:\n",
    "                return None\n",
    "            \n",
    "            # Just resize and normalize\n",
    "            resized = cv2.resize(eye_img, IMG_SIZE)\n",
    "            normalized = resized.astype('float32') / 255.0\n",
    "            \n",
    "            return np.expand_dims(normalized, axis=0)\n",
    "            \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def predict_eye(self, eye_image):\n",
    "        \"\"\"Fast prediction\"\"\"\n",
    "        if self.model is None:\n",
    "            return None, 0.0\n",
    "        \n",
    "        try:\n",
    "            processed = self.fast_preprocess(eye_image)\n",
    "            if processed is None:\n",
    "                return None, 0.0\n",
    "            \n",
    "            input_tensor = torch.tensor(processed, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_tensor)\n",
    "                confidence = output.item()\n",
    "                prediction = 1 if confidence > 0.5 else 0\n",
    "            \n",
    "            return prediction, confidence\n",
    "            \n",
    "        except:\n",
    "            return None, 0.0\n",
    "    \n",
    "    def extract_eyes_simple(self, image):\n",
    "        \"\"\"Simple eye extraction\"\"\"\n",
    "        try:\n",
    "            if len(image.shape) == 3:\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = image\n",
    "            \n",
    "            eyes = []\n",
    "            positions = []\n",
    "            \n",
    "            # Simple face detection\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "                \n",
    "                # Simple eye detection\n",
    "                detected_eyes = self.eye_cascade.detectMultiScale(face_roi, 1.1, 4)\n",
    "                \n",
    "                for (ex, ey, ew, eh) in detected_eyes[:2]:  # Max 2 eyes\n",
    "                    if ew >= 20 and eh >= 10:\n",
    "                        eye_roi = face_roi[ey:ey+eh, ex:ex+ew]\n",
    "                        eyes.append(eye_roi)\n",
    "                        positions.append((x+ex, y+ey, ew, eh))\n",
    "            \n",
    "            return eyes, positions\n",
    "            \n",
    "        except:\n",
    "            return [], []\n",
    "    \n",
    "    def analyze_simple(self, eye_states):\n",
    "        \"\"\"Simple drowsiness analysis\"\"\"\n",
    "        if not eye_states:\n",
    "            return \"NO EYES\", 0\n",
    "        \n",
    "        # Count closed eyes\n",
    "        closed_count = sum(1 for state in eye_states if state == 0)\n",
    "        \n",
    "        # Simple logic: if more than half eyes are closed\n",
    "        if closed_count > len(eye_states) / 2:\n",
    "            self.eye_close_counter += 1\n",
    "        else:\n",
    "            self.eye_close_counter = max(0, self.eye_close_counter - 1)\n",
    "        \n",
    "        # Determine status\n",
    "        if self.eye_close_counter >= self.eye_close_threshold:\n",
    "            return \"üö® DROWSY!\", self.eye_close_counter\n",
    "        elif self.eye_close_counter > self.eye_close_threshold * 0.5:\n",
    "            return \"‚ö†Ô∏è TIRED\", self.eye_close_counter\n",
    "        else:\n",
    "            return \"‚úÖ AWAKE\", self.eye_close_counter\n",
    "    \n",
    "    def process_frame_simple(self, frame, draw=True):\n",
    "        \"\"\"Simple frame processing\"\"\"\n",
    "        try:\n",
    "            # Extract eyes\n",
    "            eyes, positions = self.extract_eyes_simple(frame)\n",
    "            \n",
    "            if not eyes:\n",
    "                if draw:\n",
    "                    self.draw_simple_info(frame, \"NO EYES\", 0, 0)\n",
    "                return frame, [], \"NO EYES\"\n",
    "            \n",
    "            # Predict each eye\n",
    "            eye_states = []\n",
    "            for eye_img in eyes:\n",
    "                pred, _ = self.predict_eye(eye_img)\n",
    "                if pred is not None:\n",
    "                    eye_states.append(pred)\n",
    "            \n",
    "            # Analyze\n",
    "            status, counter = self.analyze_simple(eye_states)\n",
    "            \n",
    "            # Draw if requested\n",
    "            if draw:\n",
    "                self.draw_simple_detections(frame, positions, eye_states)\n",
    "                self.draw_simple_info(frame, status, len(eyes), counter)\n",
    "            \n",
    "            return frame, eye_states, status\n",
    "            \n",
    "        except Exception as e:\n",
    "            return frame, [], \"ERROR\"\n",
    "    \n",
    "    def draw_simple_detections(self, frame, positions, eye_states):\n",
    "        \"\"\"Simple drawing\"\"\"\n",
    "        for i, ((x, y, w, h), state) in enumerate(zip(positions, eye_states)):\n",
    "            color = (0, 255, 0) if state == 1 else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Simple label\n",
    "            label = \"O\" if state == 1 else \"C\"\n",
    "            cv2.putText(frame, label, (x, y-5), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    \n",
    "    def draw_simple_info(self, frame, status, eyes_count, counter):\n",
    "        \"\"\"Simple info display\"\"\"\n",
    "        # Status color\n",
    "        if \"üö®\" in status:\n",
    "            color = (0, 0, 255)  # Red\n",
    "        elif \"‚ö†Ô∏è\" in status:\n",
    "            color = (0, 255, 255)  # Yellow\n",
    "        else:\n",
    "            color = (0, 255, 0)  # Green\n",
    "        \n",
    "        # Simple text\n",
    "        cv2.putText(frame, status, (10, 30), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        cv2.putText(frame, f\"Eyes: {eyes_count}\", (10, 60), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, f\"Count: {counter}\", (10, 80), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    def try_camera_simple(self):\n",
    "        \"\"\"Simple camera detection\"\"\"\n",
    "        # Try different camera indices\n",
    "        for i in range(5):\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    cap.release()\n",
    "                    print(f\"üì∑ Using camera {i}\")\n",
    "                    return i\n",
    "            cap.release()\n",
    "        \n",
    "        print(\"‚ùå No camera found\")\n",
    "        return -1\n",
    "    \n",
    "    def webcam_simple(self):\n",
    "        \"\"\"Simple webcam detection\"\"\"\n",
    "        camera_index = self.try_camera_simple()\n",
    "        if camera_index == -1:\n",
    "            messagebox.showerror(\"Camera Error\", \n",
    "                               \"No camera found!\\n\\n\"\n",
    "                               \"Please check:\\n\"\n",
    "                               \"1. Camera is connected\\n\"\n",
    "                               \"2. Camera drivers are installed\\n\"\n",
    "                               \"3. No other app is using camera\")\n",
    "            return False\n",
    "        \n",
    "        cap = cv2.VideoCapture(camera_index)\n",
    "        \n",
    "        # Set lower resolution for speed\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        print(\"üé• Starting simple webcam...\")\n",
    "        print(\"üí° Press 'Q' to quit, 'R' to reset counter\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Mirror frame\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                # Process frame\n",
    "                processed_frame, _, status = self.process_frame_simple(frame)\n",
    "                \n",
    "                # Display\n",
    "                cv2.imshow('Simple Eye Detection', processed_frame)\n",
    "                \n",
    "                # Handle keys\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.eye_close_counter = 0\n",
    "                    print(\"üîÑ Counter reset\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Webcam error: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"‚úÖ Webcam stopped\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def process_image_simple(self, image_path):\n",
    "        \"\"\"Simple image processing\"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            return False, \"Image not found\"\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            return False, \"Cannot load image\"\n",
    "        \n",
    "        eyes, positions = self.extract_eyes_simple(image)\n",
    "        \n",
    "        if not eyes:\n",
    "            return False, \"No eyes detected\"\n",
    "        \n",
    "        predictions = []\n",
    "        for eye_img in eyes:\n",
    "            pred, conf = self.predict_eye(eye_img)\n",
    "            if pred is not None:\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        if not predictions:\n",
    "            return False, \"Prediction failed\"\n",
    "        \n",
    "        open_count = sum(predictions)\n",
    "        closed_count = len(predictions) - open_count\n",
    "        state = \"OPEN\" if open_count > closed_count else \"CLOSED\"\n",
    "        \n",
    "        # Show result\n",
    "        result_frame, _, _ = self.process_frame_simple(image)\n",
    "        cv2.imshow('Image Result', result_frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        result = {\n",
    "            'state': state,\n",
    "            'eyes_detected': len(eyes),\n",
    "            'open_eyes': open_count,\n",
    "            'closed_eyes': closed_count\n",
    "        }\n",
    "        \n",
    "        return True, result\n",
    "\n",
    "# ==================== CLEAN GUI ====================\n",
    "class CleanEyeDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"üëÅÔ∏è Eye Detection\")\n",
    "        self.root.geometry(\"400x300\")\n",
    "        \n",
    "        self.detector = SimpleEyeDetection()\n",
    "        self.setup_gui()\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Clean and simple GUI\"\"\"\n",
    "        # Title\n",
    "        title = tk.Label(self.root, text=\"üëÅÔ∏è EYE DETECTION\", \n",
    "                        font=('Arial', 16, 'bold'))\n",
    "        title.pack(pady=20)\n",
    "        \n",
    "        # Status\n",
    "        self.status = tk.Label(self.root, text=\"Ready to use\", \n",
    "                              font=('Arial', 12))\n",
    "        self.status.pack(pady=10)\n",
    "        \n",
    "        # Buttons frame\n",
    "        btn_frame = tk.Frame(self.root)\n",
    "        btn_frame.pack(pady=20)\n",
    "        \n",
    "        # Webcam button\n",
    "        webcam_btn = tk.Button(btn_frame, text=\"üé• Start Webcam\", \n",
    "                             command=self.start_webcam,\n",
    "                             font=('Arial', 12), bg='#4CAF50', fg='white',\n",
    "                             width=15, height=2)\n",
    "        webcam_btn.grid(row=0, column=0, padx=10, pady=10)\n",
    "        \n",
    "        # Image button\n",
    "        image_btn = tk.Button(btn_frame, text=\"üñºÔ∏è Open Image\", \n",
    "                            command=self.open_image,\n",
    "                            font=('Arial', 12), bg='#2196F3', fg='white',\n",
    "                            width=15, height=2)\n",
    "        image_btn.grid(row=0, column=1, padx=10, pady=10)\n",
    "        \n",
    "        # Reset button\n",
    "        reset_btn = tk.Button(btn_frame, text=\"üîÑ Reset\", \n",
    "                            command=self.reset_counter,\n",
    "                            font=('Arial', 12), bg='#FF9800', fg='white',\n",
    "                            width=15, height=2)\n",
    "        reset_btn.grid(row=1, column=0, padx=10, pady=10)\n",
    "        \n",
    "        # Exit button\n",
    "        exit_btn = tk.Button(btn_frame, text=\"üö™ Exit\", \n",
    "                           command=self.root.quit,\n",
    "                           font=('Arial', 12), bg='#f44336', fg='white',\n",
    "                           width=15, height=2)\n",
    "        exit_btn.grid(row=1, column=1, padx=10, pady=10)\n",
    "        \n",
    "        # Info\n",
    "        info = tk.Label(self.root, text=\"Press 'Q' to quit webcam, 'R' to reset counter\",\n",
    "                       font=('Arial', 9), fg='gray')\n",
    "        info.pack(pady=10)\n",
    "    \n",
    "    def start_webcam(self):\n",
    "        \"\"\"Start webcam in thread\"\"\"\n",
    "        def run_webcam():\n",
    "            self.status.config(text=\"Starting webcam...\", fg='orange')\n",
    "            success = self.detector.webcam_simple()\n",
    "            if success:\n",
    "                self.status.config(text=\"Webcam finished\", fg='green')\n",
    "            else:\n",
    "                self.status.config(text=\"Webcam failed\", fg='red')\n",
    "        \n",
    "        threading.Thread(target=run_webcam, daemon=True).start()\n",
    "    \n",
    "    def open_image(self):\n",
    "        \"\"\"Open and process image\"\"\"\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select Image\",\n",
    "            filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            def process():\n",
    "                self.status.config(text=\"Processing image...\", fg='orange')\n",
    "                success, result = self.detector.process_image_simple(file_path)\n",
    "                \n",
    "                if success:\n",
    "                    self.status.config(text=\"Image processed\", fg='green')\n",
    "                    messagebox.showinfo(\"Result\", \n",
    "                                      f\"State: {result['state']}\\n\"\n",
    "                                      f\"Eyes detected: {result['eyes_detected']}\\n\"\n",
    "                                      f\"Open eyes: {result['open_eyes']}\\n\"\n",
    "                                      f\"Closed eyes: {result['closed_eyes']}\")\n",
    "                else:\n",
    "                    self.status.config(text=\"Image failed\", fg='red')\n",
    "                    messagebox.showerror(\"Error\", result)\n",
    "            \n",
    "            threading.Thread(target=process, daemon=True).start()\n",
    "    \n",
    "    def reset_counter(self):\n",
    "        \"\"\"Reset drowsiness counter\"\"\"\n",
    "        self.detector.eye_close_counter = 0\n",
    "        self.status.config(text=\"Counter reset\", fg='blue')\n",
    "        messagebox.showinfo(\"Reset\", \"Drowsiness counter has been reset!\")\n",
    "\n",
    "# ==================== DIRECT TEST (without GUI) ====================\n",
    "def test_system():\n",
    "    \"\"\"Test the system directly\"\"\"\n",
    "    print(\"üß™ Testing Eye Detection System...\")\n",
    "    \n",
    "    detector = SimpleEyeDetection()\n",
    "    if not detector.model:\n",
    "        print(\"‚ùå TEST FAILED: Model not loaded\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # Test with webcam\n",
    "    print(\"üé• Testing webcam...\")\n",
    "    webcam_works = detector.webcam_simple()\n",
    "    \n",
    "    if webcam_works:\n",
    "        print(\"‚úÖ Webcam test PASSED\")\n",
    "    else:\n",
    "        print(\"‚ùå Webcam test FAILED\")\n",
    "    \n",
    "    return webcam_works\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "def main():\n",
    "    print(\"üöÄ Starting Simple Eye Detection System...\")\n",
    "    \n",
    "    # Test if model loads\n",
    "    detector = SimpleEyeDetection()\n",
    "    if not detector.model:\n",
    "        print(\"‚ùå Cannot start: Model loading failed\")\n",
    "        print(\"üí° Please check:\")\n",
    "        print(\"   1. Model file exists\")\n",
    "        print(\"   2. File path is correct\") \n",
    "        print(\"   3. PyTorch is properly installed\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ System ready!\")\n",
    "    \n",
    "    # Start GUI\n",
    "    root = tk.Tk()\n",
    "    app = CleanEyeDetectionApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d013290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ BIAS-CORRECTED EYE DETECTION SYSTEM\n",
      "==================================================\n",
      "üß™ Running Quick Bias Test...\n",
      "‚úÖ Checkpoint loaded\n",
      "‚ùå Error loading model: Error(s) in loading state_dict for BiasAwareEyeModel:\n",
      "\tsize mismatch for features.5.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "üéØ Bias-Corrected Eye Detection Ready!\n",
      "   Dark image: CLOSED (conf: 0.476) - SUCCESS\n",
      "   Low contrast: OPEN (conf: 0.617) - SUCCESS\n",
      "   Mixed: CLOSED (conf: 0.301) - SUCCESS\n",
      "‚úÖ Checkpoint loaded\n",
      "‚ùå Error loading model: Error(s) in loading state_dict for BiasAwareEyeModel:\n",
      "\tsize mismatch for features.5.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "üéØ Bias-Corrected Eye Detection Ready!\n",
      "\n",
      "üöÄ Starting main system...\n",
      "üé• Starting bias-corrected detection on camera 0...\n",
      "üîß Features enabled:\n",
      "   ‚Ä¢ Dynamic threshold adjustment\n",
      "   ‚Ä¢ Image feature analysis\n",
      "   ‚Ä¢ Temporal smoothing\n",
      "   ‚Ä¢ Confidence-based correction\n",
      "üí° Press 'Q' to quit, 'T' to toggle threshold\n",
      "‚úÖ Bias-corrected detection stopped\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "MODEL_PATH = '/home/gess/Documents/eye_detection_model/professional_eye_detector.pth'\n",
    "IMG_SIZE = (64, 64)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==================== BIAS-AWARE MODEL ====================\n",
    "class BiasAwareEyeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiasAwareEyeModel, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ==================== BIAS CORRECTION SYSTEM ====================\n",
    "class BiasCorrectedDetection:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.load_model()\n",
    "        \n",
    "        # Face and eye detection\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        \n",
    "        # Bias correction\n",
    "        self.prediction_history = []\n",
    "        self.history_size = 5\n",
    "        self.confidence_threshold = 0.7  # Higher threshold for certainty\n",
    "        \n",
    "        # Dynamic threshold for bias correction\n",
    "        self.dynamic_threshold = 0.5\n",
    "        self.adjustment_factor = 0.1\n",
    "        \n",
    "        print(\"üéØ Bias-Corrected Eye Detection Ready!\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load model with bias awareness\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(MODEL_PATH):\n",
    "                print(f\"‚ùå Model not found: {MODEL_PATH}\")\n",
    "                return False\n",
    "            \n",
    "            checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "            print(\"‚úÖ Checkpoint loaded\")\n",
    "            \n",
    "            self.model = BiasAwareEyeModel().to(device)\n",
    "            \n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "            else:\n",
    "                self.model.load_state_dict(checkpoint, strict=False)\n",
    "            \n",
    "            self.model.eval()\n",
    "            print(\"‚úÖ Model loaded with bias correction\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def analyze_eye_features(self, eye_img):\n",
    "        \"\"\"Analyze eye image features to help with bias correction\"\"\"\n",
    "        try:\n",
    "            if eye_img is None:\n",
    "                return None\n",
    "            \n",
    "            # Calculate image statistics that might indicate closed eyes\n",
    "            mean_intensity = np.mean(eye_img)\n",
    "            std_intensity = np.std(eye_img)\n",
    "            \n",
    "            # Closed eyes often have lower contrast and different intensity distribution\n",
    "            contrast = std_intensity / (mean_intensity + 1e-6)\n",
    "            \n",
    "            # Calculate percentage of dark pixels (potential closed eyes)\n",
    "            dark_pixels = np.sum(eye_img < 50) / eye_img.size\n",
    "            \n",
    "            features = {\n",
    "                'mean_intensity': mean_intensity,\n",
    "                'contrast': contrast,\n",
    "                'dark_pixels': dark_pixels\n",
    "            }\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def bias_aware_preprocess(self, eye_img):\n",
    "        \"\"\"Preprocessing with bias consideration\"\"\"\n",
    "        try:\n",
    "            if eye_img is None or eye_img.size == 0:\n",
    "                return None\n",
    "            \n",
    "            # Resize\n",
    "            resized = cv2.resize(eye_img, IMG_SIZE)\n",
    "            \n",
    "            # Apply CLAHE for better contrast - especially helpful for closed eyes\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            enhanced = clahe.apply(resized)\n",
    "            \n",
    "            # Normalize\n",
    "            normalized = enhanced.astype('float32') / 255.0\n",
    "            \n",
    "            return np.expand_dims(normalized, axis=0)\n",
    "            \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def adjust_prediction_with_features(self, prediction, confidence, features):\n",
    "        \"\"\"Adjust prediction based on image features\"\"\"\n",
    "        if features is None:\n",
    "            return prediction, confidence\n",
    "        \n",
    "        # If image is very dark and low contrast, likely closed eyes\n",
    "        if features['mean_intensity'] < 80 and features['contrast'] < 0.5:\n",
    "            if prediction == 1:  # If model says open but features say closed\n",
    "                if confidence < 0.8:  # Only adjust if not very confident\n",
    "                    return 0, 1 - confidence  # Flip prediction\n",
    "                    \n",
    "        # If many dark pixels, might be closed eyes\n",
    "        if features['dark_pixels'] > 0.3 and confidence < 0.7:\n",
    "            if prediction == 1:\n",
    "                return 0, 1 - confidence\n",
    "                \n",
    "        return prediction, confidence\n",
    "    \n",
    "    def predict_with_bias_correction(self, eye_image):\n",
    "        \"\"\"Predict with bias correction mechanisms\"\"\"\n",
    "        if self.model is None:\n",
    "            return None, 0.0, \"NO MODEL\"\n",
    "        \n",
    "        try:\n",
    "            # Preprocess\n",
    "            processed = self.bias_aware_preprocess(eye_image)\n",
    "            if processed is None:\n",
    "                return None, 0.0, \"PREPROCESS FAILED\"\n",
    "            \n",
    "            # Get image features for bias correction\n",
    "            features = self.analyze_eye_features(eye_image)\n",
    "            \n",
    "            # Model prediction\n",
    "            input_tensor = torch.tensor(processed, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_tensor)\n",
    "                raw_confidence = output.item()\n",
    "                \n",
    "                # ADJUSTABLE THRESHOLD - try different values\n",
    "                current_threshold = self.dynamic_threshold\n",
    "                raw_prediction = 1 if raw_confidence > current_threshold else 0\n",
    "                \n",
    "                # Apply bias correction based on image features\n",
    "                final_prediction, final_confidence = self.adjust_prediction_with_features(\n",
    "                    raw_prediction, raw_confidence, features\n",
    "                )\n",
    "                \n",
    "                # Update dynamic threshold based on confidence\n",
    "                if final_confidence > 0.8:\n",
    "                    # Good confidence, keep threshold\n",
    "                    pass\n",
    "                elif final_confidence < 0.6:\n",
    "                    # Low confidence, adjust threshold\n",
    "                    self.dynamic_threshold += 0.05\n",
    "                else:\n",
    "                    # Medium confidence, slight adjustment\n",
    "                    self.dynamic_threshold += 0.02\n",
    "                \n",
    "                # Keep threshold in reasonable range\n",
    "                self.dynamic_threshold = max(0.3, min(0.7, self.dynamic_threshold))\n",
    "                \n",
    "                # Store prediction for temporal smoothing\n",
    "                self.prediction_history.append(final_prediction)\n",
    "                if len(self.prediction_history) > self.history_size:\n",
    "                    self.prediction_history.pop(0)\n",
    "                \n",
    "                # Apply temporal smoothing (majority vote from recent frames)\n",
    "                if len(self.prediction_history) >= 3:\n",
    "                    recent_majority = 1 if sum(self.prediction_history) > len(self.prediction_history) / 2 else 0\n",
    "                    if recent_majority != final_prediction and final_confidence < 0.7:\n",
    "                        final_prediction = recent_majority\n",
    "                        final_confidence = 0.6  # Moderate confidence for smoothed prediction\n",
    "            \n",
    "            return final_prediction, final_confidence, \"SUCCESS\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, 0.0, f\"ERROR: {e}\"\n",
    "    \n",
    "    def extract_eyes_robust(self, image):\n",
    "        \"\"\"Robust eye extraction with multiple attempts\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            eyes = []\n",
    "            positions = []\n",
    "            \n",
    "            # Improve face detection with better parameters\n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                gray, \n",
    "                scaleFactor=1.05,\n",
    "                minNeighbors=6,\n",
    "                minSize=(50, 50),\n",
    "                flags=cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "                \n",
    "                # Try multiple eye detection parameters\n",
    "                eye_params = [\n",
    "                    {'scale': 1.05, 'neighbors': 3, 'minSize': (20, 10)},  # Sensitive\n",
    "                    {'scale': 1.1, 'neighbors': 5, 'minSize': (25, 15)},   # Balanced\n",
    "                    {'scale': 1.02, 'neighbors': 2, 'minSize': (15, 8)},   # Very sensitive\n",
    "                ]\n",
    "                \n",
    "                all_eyes = []\n",
    "                for params in eye_params:\n",
    "                    detected = self.eye_cascade.detectMultiScale(\n",
    "                        face_roi,\n",
    "                        scaleFactor=params['scale'],\n",
    "                        minNeighbors=params['neighbors'],\n",
    "                        minSize=params['minSize']\n",
    "                    )\n",
    "                    all_eyes.extend(detected)\n",
    "                \n",
    "                # Remove duplicates and take best 2 eyes\n",
    "                unique_eyes = []\n",
    "                for eye in all_eyes:\n",
    "                    if len(unique_eyes) >= 2:\n",
    "                        break\n",
    "                    # Simple duplicate check\n",
    "                    is_duplicate = False\n",
    "                    for u_eye in unique_eyes:\n",
    "                        if abs(eye[0] - u_eye[0]) < 10 and abs(eye[1] - u_eye[1]) < 10:\n",
    "                            is_duplicate = True\n",
    "                            break\n",
    "                    if not is_duplicate:\n",
    "                        unique_eyes.append(eye)\n",
    "                \n",
    "                for (ex, ey, ew, eh) in unique_eyes:\n",
    "                    eye_roi = face_roi[ey:ey+eh, ex:ex+ew]\n",
    "                    eyes.append(eye_roi)\n",
    "                    positions.append((x+ex, y+ey, ew, eh))\n",
    "            \n",
    "            return eyes, positions\n",
    "            \n",
    "        except Exception as e:\n",
    "            return [], []\n",
    "    \n",
    "    def process_frame_with_correction(self, frame):\n",
    "        \"\"\"Process frame with comprehensive bias correction\"\"\"\n",
    "        try:\n",
    "            eyes, positions = self.extract_eyes_robust(frame)\n",
    "            \n",
    "            predictions = []\n",
    "            states = []\n",
    "            \n",
    "            for i, (eye_img, (x, y, w, h)) in enumerate(zip(eyes, positions)):\n",
    "                prediction, confidence, status = self.predict_with_bias_correction(eye_img)\n",
    "                \n",
    "                if prediction is not None:\n",
    "                    state = \"OPEN\" if prediction == 1 else \"CLOSED\"\n",
    "                    display_confidence = confidence if prediction == 1 else 1 - confidence\n",
    "                    \n",
    "                    predictions.append((state, display_confidence))\n",
    "                    states.append(prediction)\n",
    "                    \n",
    "                    # Visual feedback with confidence indication\n",
    "                    if confidence > 0.8:\n",
    "                        color = (0, 255, 0) if state == \"OPEN\" else (0, 0, 255)\n",
    "                        thickness = 3\n",
    "                    elif confidence > 0.6:\n",
    "                        color = (0, 200, 0) if state == \"OPEN\" else (0, 0, 200) \n",
    "                        thickness = 2\n",
    "                    else:\n",
    "                        color = (0, 150, 0) if state == \"OPEN\" else (0, 0, 150)\n",
    "                        thickness = 1\n",
    "                    \n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)\n",
    "                    \n",
    "                    # Text with confidence\n",
    "                    text = f\"{state} ({display_confidence:.2f})\"\n",
    "                    cv2.putText(frame, text, (x, y-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "            return frame, predictions\n",
    "            \n",
    "        except Exception as e:\n",
    "            return frame, []\n",
    "    \n",
    "    def run_bias_corrected_webcam(self):\n",
    "        \"\"\"Run webcam with bias correction\"\"\"\n",
    "        # Find camera\n",
    "        for i in range(5):\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap.isOpened():\n",
    "                ret, _ = cap.read()\n",
    "                if ret:\n",
    "                    break\n",
    "            cap.release()\n",
    "        else:\n",
    "            print(\"‚ùå No camera found!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üé• Starting bias-corrected detection on camera {i}...\")\n",
    "        print(\"üîß Features enabled:\")\n",
    "        print(\"   ‚Ä¢ Dynamic threshold adjustment\")\n",
    "        print(\"   ‚Ä¢ Image feature analysis\") \n",
    "        print(\"   ‚Ä¢ Temporal smoothing\")\n",
    "        print(\"   ‚Ä¢ Confidence-based correction\")\n",
    "        print(\"üí° Press 'Q' to quit, 'T' to toggle threshold\")\n",
    "        \n",
    "        threshold_display = True\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                # Process with bias correction\n",
    "                processed_frame, predictions = self.process_frame_with_correction(frame)\n",
    "                \n",
    "                # Display current threshold\n",
    "                if threshold_display:\n",
    "                    cv2.putText(processed_frame, f\"Threshold: {self.dynamic_threshold:.2f}\", \n",
    "                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "                \n",
    "                cv2.putText(processed_frame, \"Press 'Q' to quit, 'T' toggle threshold\", \n",
    "                          (10, processed_frame.shape[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "                \n",
    "                cv2.imshow('Bias-Corrected Eye Detection', processed_frame)\n",
    "                \n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('t'):\n",
    "                    threshold_display = not threshold_display\n",
    "                elif key == ord('+'):\n",
    "                    self.dynamic_threshold = min(0.7, self.dynamic_threshold + 0.05)\n",
    "                elif key == ord('-'):\n",
    "                    self.dynamic_threshold = max(0.3, self.dynamic_threshold - 0.05)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"‚úÖ Bias-corrected detection stopped\")\n",
    "\n",
    "# ==================== QUICK BIAS TEST ====================\n",
    "def quick_bias_test():\n",
    "    \"\"\"Quick test to check model bias\"\"\"\n",
    "    print(\"üß™ Running Quick Bias Test...\")\n",
    "    \n",
    "    detector = BiasCorrectedDetection()\n",
    "    if not detector.model:\n",
    "        print(\"‚ùå Cannot test without model\")\n",
    "        return\n",
    "    \n",
    "    # Test with sample patterns that should be closed eyes\n",
    "    test_cases = [\n",
    "        (\"Dark image\", np.zeros((50, 50), dtype=np.uint8)),\n",
    "        (\"Low contrast\", np.full((50, 50), 100, dtype=np.uint8)),\n",
    "        (\"Mixed\", np.random.randint(0, 50, (50, 50), dtype=np.uint8)),\n",
    "    ]\n",
    "    \n",
    "    for name, test_img in test_cases:\n",
    "        prediction, confidence, status = detector.predict_with_bias_correction(test_img)\n",
    "        if prediction is not None:\n",
    "            state = \"OPEN\" if prediction == 1 else \"CLOSED\"\n",
    "            print(f\"   {name}: {state} (conf: {confidence:.3f}) - {status}\")\n",
    "        else:\n",
    "            print(f\"   {name}: FAILED - {status}\")\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "def main():\n",
    "    print(\"üéØ BIAS-CORRECTED EYE DETECTION SYSTEM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Quick bias test\n",
    "    quick_bias_test()\n",
    "    \n",
    "    # Main system\n",
    "    detector = BiasCorrectedDetection()\n",
    "    if not detector.model:\n",
    "        print(\"‚ùå Cannot start without model\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüöÄ Starting main system...\")\n",
    "    detector.run_bias_corrected_webcam()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fbea35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# ===========================\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N & THAM S·ªê\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ===========================\u001b[39;00m\n\u001b[1;32m     21\u001b[0m DATA_ROOT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/gess/Documents/sub/TrainModel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Deque, Tuple, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ===========================\n",
    "# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N & THAM S·ªê\n",
    "# ===========================\n",
    "\n",
    "DATA_ROOT = Path(\"/home/gess/Documents/sub/TrainModel\")\n",
    "MODEL_DIR = DATA_ROOT / \"models\"\n",
    "BEST_MODEL = MODEL_DIR / \"best_drowsy.pt\"  # ƒë√£ train xong ·ªü train_drowsy.py\n",
    "\n",
    "# Class name ph·∫£i tr√πng l√∫c train\n",
    "CLS_OPEN = \"open_eye\"\n",
    "CLS_CLOSED = \"closed_eye\"\n",
    "\n",
    "# Tham s·ªë drowsy\n",
    "HISTORY_LEN = 30        # s·ªë frame l∆∞u history (kho·∫£ng 1 gi√¢y n·∫øu 30fps)\n",
    "DROWSY_THRESHOLD = 0.6  # t·ªâ l·ªá closed_eye / (open+closed) trong history\n",
    "MIN_EYES_PER_FRAME = 1  # s·ªë m·∫Øt min ƒë·ªÉ frame ƒë∆∞·ª£c t√≠nh\n",
    "\n",
    "# Confidence ng∆∞·ª°ng ƒë·ªÉ t√≠nh\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ===========================\n",
    "# H√ÄM TI·ªÜN √çCH\n",
    "# ===========================\n",
    "\n",
    "def load_model(model_path: Path) -> YOLO:\n",
    "    if not model_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y model: {model_path}\")\n",
    "        sys.exit(1)\n",
    "    print(f\"[üöÄ] Load model: {model_path}\")\n",
    "    model = YOLO(str(model_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def decode_counts_from_result(\n",
    "    result,\n",
    "    cls_open: str = CLS_OPEN,\n",
    "    cls_closed: str = CLS_CLOSED,\n",
    "    conf_thresh: float = CONF_THRESH,\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    ƒê·∫øm s·ªë open_eye v√† closed_eye trong 1 k·∫øt qu·∫£ YOLO.\n",
    "\n",
    "    Return:\n",
    "        (num_open, num_closed)\n",
    "    \"\"\"\n",
    "    names = result.names\n",
    "    num_open = 0\n",
    "    num_closed = 0\n",
    "\n",
    "    if result.boxes is None or len(result.boxes) == 0:\n",
    "        return 0, 0\n",
    "\n",
    "    for b in result.boxes:\n",
    "        cls_id = int(b.cls[0].item())\n",
    "        conf = float(b.conf[0].item())\n",
    "        if conf < conf_thresh:\n",
    "            continue\n",
    "        cls_name = names.get(cls_id, str(cls_id))\n",
    "        if cls_name == cls_open:\n",
    "            num_open += 1\n",
    "        elif cls_name == cls_closed:\n",
    "            num_closed += 1\n",
    "    return num_open, num_closed\n",
    "\n",
    "\n",
    "def update_drowsy_history(\n",
    "    history: Deque[Tuple[int, int]],\n",
    "    num_open: int,\n",
    "    num_closed: int,\n",
    "    maxlen: int = HISTORY_LEN,\n",
    ") -> Tuple[float, int, int]:\n",
    "    \"\"\"\n",
    "    C·∫≠p nh·∫≠t history (deque) v·ªõi (open, closed) c·ªßa frame m·ªõi.\n",
    "    Tr·∫£ v·ªÅ:\n",
    "        - closed_ratio (t·ªâ l·ªá closed / total)\n",
    "        - total_open\n",
    "        - total_closed\n",
    "    \"\"\"\n",
    "    history.append((num_open, num_closed))\n",
    "    if len(history) > maxlen:\n",
    "        history.popleft()\n",
    "\n",
    "    total_open = sum(o for o, _ in history)\n",
    "    total_closed = sum(c for _, c in history)\n",
    "    total = total_open + total_closed\n",
    "    closed_ratio = (total_closed / total) if total > 0 else 0.0\n",
    "    return closed_ratio, total_open, total_closed\n",
    "\n",
    "\n",
    "def draw_info(\n",
    "    frame: np.ndarray,\n",
    "    num_open: int,\n",
    "    num_closed: int,\n",
    "    closed_ratio: float,\n",
    "    is_drowsy: bool,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    V·∫Ω th√¥ng tin l√™n frame: s·ªë m·∫Øt m·ªü/nh·∫Øm, t·ªâ l·ªá, tr·∫°ng th√°i drowsy.\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Bar m·ªù ph√≠a tr√™n\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 80), (0, 0, 0), -1)\n",
    "    alpha = 0.4\n",
    "    frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "    # Text info\n",
    "    base_y = 25\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Open: {num_open}  Closed: {num_closed}\",\n",
    "        (10, base_y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Closed ratio: {closed_ratio:.2f}\",\n",
    "        (10, base_y + 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (255, 255, 0),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "    status_text = \"DROWSY!\" if is_drowsy else \"OK\"\n",
    "    color = (0, 0, 255) if is_drowsy else (0, 255, 0)\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Status: {status_text}\",\n",
    "        (10, base_y + 50),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.8,\n",
    "        color,\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "    # N·∫øu drowsy th√¨ v·∫Ω khung c·∫£nh b√°o\n",
    "    if is_drowsy:\n",
    "        cv2.rectangle(frame, (0, 80), (w - 1, h - 1), (0, 0, 255), 4)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# WEBCAM REALTIME\n",
    "# ===========================\n",
    "\n",
    "def run_webcam(\n",
    "    model: YOLO,\n",
    "    cam_index: int = 0,\n",
    "    history_len: int = HISTORY_LEN,\n",
    "    drowsy_thresh: float = DROWSY_THRESHOLD,\n",
    "):\n",
    "    print(f\"[üé•] ƒêang m·ªü webcam {cam_index}...\")\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[‚ùå] Kh√¥ng m·ªü ƒë∆∞·ª£c webcam, th·ª≠ index kh√°c (0,1,2,...) ho·∫∑c ki·ªÉm tra quy·ªÅn.\")\n",
    "        return\n",
    "\n",
    "    history: Deque[Tuple[int, int]] = deque(maxlen=history_len)\n",
    "\n",
    "    print(\"[INFO] Nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[‚ùå] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame t·ª´ webcam.\")\n",
    "            break\n",
    "\n",
    "        # YOLO expect BGR ‚Üí OK\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            imgsz=768,\n",
    "            conf=CONF_THRESH,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        if len(results) == 0:\n",
    "            num_open, num_closed = 0, 0\n",
    "        else:\n",
    "            num_open, num_closed = decode_counts_from_result(results[0])\n",
    "\n",
    "        closed_ratio, total_open, total_closed = update_drowsy_history(\n",
    "            history, num_open, num_closed, maxlen=history_len\n",
    "        )\n",
    "\n",
    "        is_drowsy = False\n",
    "        total = total_open + total_closed\n",
    "        if total >= MIN_EYES_PER_FRAME and closed_ratio >= drowsy_thresh:\n",
    "            is_drowsy = True\n",
    "\n",
    "        # V·∫Ω detection box c·ªßa YOLO\n",
    "        plotted = results[0].plot() if len(results) > 0 else frame.copy()\n",
    "\n",
    "        # V·∫Ω info Drowsy\n",
    "        plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "\n",
    "        cv2.imshow(\"Drowsy Detection - Webcam\", plotted)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[‚úÖ] ƒê√£ tho√°t realtime.\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH 1 ·∫¢NH\n",
    "# ===========================\n",
    "\n",
    "def analyze_image(model: YOLO, img_path: str | Path):\n",
    "    img_path = Path(img_path)\n",
    "    if not img_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y ·∫£nh: {img_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"[‚ùå] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {img_path}\")\n",
    "        return\n",
    "\n",
    "    results = model.predict(\n",
    "        source=img,\n",
    "        imgsz=768,\n",
    "        conf=CONF_THRESH,\n",
    "        verbose=False,\n",
    "    )\n",
    "    if len(results) == 0:\n",
    "        print(\"[‚Ñπ] Kh√¥ng c√≥ detection n√†o.\")\n",
    "        cv2.imshow(\"Drowsy - Image\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "    r = results[0]\n",
    "    num_open, num_closed = decode_counts_from_result(r)\n",
    "    total = num_open + num_closed\n",
    "    closed_ratio = (num_closed / total) if total > 0 else 0.0\n",
    "    is_drowsy = closed_ratio >= DROWSY_THRESHOLD and total >= MIN_EYES_PER_FRAME\n",
    "\n",
    "    print(\"===== PH√ÇN T√çCH ·∫¢NH =====\")\n",
    "    print(f\"·∫¢nh       : {img_path}\")\n",
    "    print(f\"Open eyes : {num_open}\")\n",
    "    print(f\"Closed    : {num_closed}\")\n",
    "    print(f\"Closed ratio: {closed_ratio:.2f}\")\n",
    "    print(f\"Tr·∫°ng th√°i: {'DROWSY' if is_drowsy else 'OK'}\")\n",
    "\n",
    "    plotted = r.plot()\n",
    "    plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "    cv2.imshow(\"Drowsy - Image\", plotted)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH FOLDER ·∫¢NH\n",
    "# ===========================\n",
    "\n",
    "def analyze_folder(model: YOLO, folder: str | Path):\n",
    "    folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y folder: {folder}\")\n",
    "        return\n",
    "\n",
    "    exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "    img_files = sorted(\n",
    "        [p for p in folder.rglob(\"*\") if p.suffix.lower() in exts]\n",
    "    )\n",
    "    if not img_files:\n",
    "        print(f\"[‚Ñπ] Folder kh√¥ng c√≥ ·∫£nh h·ª£p l·ªá: {folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[üìÇ] T√¨m th·∫•y {len(img_files)} ·∫£nh trong {folder}\")\n",
    "    for img_path in img_files:\n",
    "        print(f\"\\n--- {img_path} ---\")\n",
    "        analyze_image(model, img_path)\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# PH√ÇN T√çCH VIDEO\n",
    "# ===========================\n",
    "\n",
    "def analyze_video(\n",
    "    model: YOLO,\n",
    "    video_path: str | Path,\n",
    "    history_len: int = HISTORY_LEN,\n",
    "    drowsy_thresh: float = DROWSY_THRESHOLD,\n",
    "):\n",
    "    video_path = Path(video_path)\n",
    "    if not video_path.exists():\n",
    "        print(f\"[‚ùå] Kh√¥ng t√¨m th·∫•y video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[‚ùå] Kh√¥ng m·ªü ƒë∆∞·ª£c video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    history: Deque[Tuple[int, int]] = deque(maxlen=history_len)\n",
    "    print(\"[INFO] Nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            imgsz=768,\n",
    "            conf=CONF_THRESH,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        if len(results) == 0:\n",
    "            num_open, num_closed = 0, 0\n",
    "        else:\n",
    "            num_open, num_closed = decode_counts_from_result(results[0])\n",
    "\n",
    "        closed_ratio, total_open, total_closed = update_drowsy_history(\n",
    "            history, num_open, num_closed, maxlen=history_len\n",
    "        )\n",
    "        total = total_open + total_closed\n",
    "        is_drowsy = (total >= MIN_EYES_PER_FRAME) and (closed_ratio >= drowsy_thresh)\n",
    "\n",
    "        plotted = results[0].plot() if len(results) > 0 else frame.copy()\n",
    "        plotted = draw_info(plotted, num_open, num_closed, closed_ratio, is_drowsy)\n",
    "\n",
    "        cv2.imshow(\"Drowsy Detection - Video\", plotted)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[‚úÖ] ƒê√£ xong video.\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# MAIN: MENU ƒê∆†N GI·∫¢N (KH√îNG C·∫¶N CLI)\n",
    "# ===========================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ch·∫°y tr·ª±c ti·∫øp file (VS Code Run) ‚Üí hi·ªán menu:\n",
    "      1. Webcam\n",
    "      2. ·∫¢nh\n",
    "      3. Folder ·∫£nh\n",
    "      4. Video\n",
    "    \"\"\"\n",
    "    model = load_model(BEST_MODEL)\n",
    "\n",
    "    print(\"\\n====================\")\n",
    "    print(\"  DROWSY DETECTION  \")\n",
    "    print(\"====================\")\n",
    "    print(\"1) Webcam realtime\")\n",
    "    print(\"2) Ph√¢n t√≠ch 1 ·∫£nh\")\n",
    "    print(\"3) Ph√¢n t√≠ch 1 folder ·∫£nh\")\n",
    "    print(\"4) Ph√¢n t√≠ch 1 video\")\n",
    "    print(\"0) Tho√°t\")\n",
    "    choice = input(\"Ch·ªçn mode (0-4): \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        idx = input(\"Nh·∫≠p camera index (m·∫∑c ƒë·ªãnh 0): \").strip()\n",
    "        cam_idx = int(idx) if idx else 0\n",
    "        run_webcam(model, cam_index=cam_idx)\n",
    "    elif choice == \"2\":\n",
    "        path = input(\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: \").strip()\n",
    "        analyze_image(model, path)\n",
    "    elif choice == \"3\":\n",
    "        folder = input(\"Nh·∫≠p folder ·∫£nh: \").strip()\n",
    "        analyze_folder(model, folder)\n",
    "    elif choice == \"4\":\n",
    "        path = input(\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n video: \").strip()\n",
    "        analyze_video(model, path)\n",
    "    else:\n",
    "        print(\"Tho√°t.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
